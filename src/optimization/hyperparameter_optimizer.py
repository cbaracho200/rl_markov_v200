"""
Sistema de Otimiza√ß√£o Recursiva de Hiperpar√¢metros usando Optuna.

Otimiza automaticamente hiperpar√¢metros dos modelos durante o treinamento.
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Callable, Any, Union
import warnings
warnings.filterwarnings('ignore')


class HyperparameterOptimizer:
    """
    Otimizador de hiperpar√¢metros usando Optuna (Bayesian Optimization).

    Caracter√≠sticas:
    - Otimiza√ß√£o bayesiana (mais eficiente que grid search)
    - Pruning autom√°tico de trials ruins
    - Suporte a m√∫ltiplos modelos simultaneamente
    - Otimiza√ß√£o recursiva durante treinamento
    - Hist√≥rico completo de trials
    """

    def __init__(
        self,
        metric: str = 'mape',
        direction: str = 'minimize',
        n_trials: int = 50,
        timeout: Optional[int] = None,
        n_jobs: int = 1,
        verbose: bool = True
    ):
        """
        Inicializa o otimizador.

        Args:
            metric: M√©trica a otimizar ('mape', 'rmse', 'mae', etc)
            direction: 'minimize' ou 'maximize'
            n_trials: N√∫mero de trials para otimiza√ß√£o
            timeout: Tempo m√°ximo em segundos (None = sem limite)
            n_jobs: N√∫mero de jobs paralelos
            verbose: Se True, mostra progresso
        """
        try:
            import optuna
            optuna.logging.set_verbosity(optuna.logging.WARNING)
        except ImportError:
            raise ImportError("Optuna n√£o instalado. Instale com: pip install optuna")

        self.metric = metric
        self.direction = direction
        self.n_trials = n_trials
        self.timeout = timeout
        self.n_jobs = n_jobs
        self.verbose = verbose

        self.study = None
        self.best_params = {}
        self.optimization_history = []

    def optimize_model(
        self,
        model_class: Any,
        train_data: Union[np.ndarray, pd.Series],
        val_data: Union[np.ndarray, pd.Series],
        param_space: Dict[str, tuple],
        forecast_horizon: int = 12
    ) -> Dict[str, Any]:
        """
        Otimiza hiperpar√¢metros de um modelo.

        Args:
            model_class: Classe do modelo a otimizar
            train_data: Dados de treino
            val_data: Dados de valida√ß√£o
            param_space: Espa√ßo de busca dos par√¢metros
            forecast_horizon: Horizonte de previs√£o

        Returns:
            Melhores par√¢metros encontrados
        """
        import optuna

        def objective(trial):
            """Fun√ß√£o objetivo para Optuna."""
            # Sugere hiperpar√¢metros
            params = {}
            for param_name, param_config in param_space.items():
                param_type = param_config[0]

                if param_type == 'int':
                    params[param_name] = trial.suggest_int(
                        param_name,
                        param_config[1],
                        param_config[2]
                    )
                elif param_type == 'float':
                    if len(param_config) > 3 and param_config[3] == 'log':
                        params[param_name] = trial.suggest_float(
                            param_name,
                            param_config[1],
                            param_config[2],
                            log=True
                        )
                    else:
                        params[param_name] = trial.suggest_float(
                            param_name,
                            param_config[1],
                            param_config[2]
                        )
                elif param_type == 'categorical':
                    params[param_name] = trial.suggest_categorical(
                        param_name,
                        param_config[1]
                    )

            try:
                # Cria e treina modelo
                model = model_class(**params)
                model.fit(train_data)

                # Faz previs√£o
                predictions = model.predict(steps=min(forecast_horizon, len(val_data)))
                actual = val_data[:len(predictions)]

                # Calcula m√©trica
                if self.metric == 'mape':
                    score = np.mean(np.abs((actual - predictions) / (actual + 1e-8))) * 100
                elif self.metric == 'rmse':
                    score = np.sqrt(np.mean((actual - predictions) ** 2))
                elif self.metric == 'mae':
                    score = np.mean(np.abs(actual - predictions))
                elif self.metric == 'r2':
                    ss_res = np.sum((actual - predictions) ** 2)
                    ss_tot = np.sum((actual - np.mean(actual)) ** 2)
                    score = 1 - (ss_res / ss_tot)
                else:
                    raise ValueError(f"M√©trica desconhecida: {self.metric}")

                return score

            except Exception as e:
                if self.verbose:
                    print(f"  Trial falhou: {e}")
                # Retorna valor ruim para pruning
                return float('inf') if self.direction == 'minimize' else float('-inf')

        # Cria study
        self.study = optuna.create_study(
            direction=self.direction,
            study_name=f"optimize_{model_class.__name__}"
        )

        # Otimiza
        if self.verbose:
            print(f"\nüîç Otimizando {model_class.__name__}...")
            print(f"   Trials: {self.n_trials}")
            print(f"   M√©trica: {self.metric} ({self.direction})")

        self.study.optimize(
            objective,
            n_trials=self.n_trials,
            timeout=self.timeout,
            n_jobs=self.n_jobs,
            show_progress_bar=self.verbose
        )

        # Salva melhores par√¢metros
        self.best_params[model_class.__name__] = self.study.best_params

        if self.verbose:
            print(f"\n‚úÖ Otimiza√ß√£o conclu√≠da!")
            print(f"   Melhor {self.metric}: {self.study.best_value:.4f}")
            print(f"   Melhores par√¢metros:")
            for param, value in self.study.best_params.items():
                print(f"      {param}: {value}")

        # Salva hist√≥rico
        self.optimization_history.append({
            'model': model_class.__name__,
            'best_params': self.study.best_params.copy(),
            'best_score': self.study.best_value,
            'n_trials': len(self.study.trials)
        })

        return self.study.best_params

    def optimize_ensemble(
        self,
        model_configs: List[Dict],
        train_data: Union[np.ndarray, pd.Series],
        val_data: Union[np.ndarray, pd.Series],
        forecast_horizon: int = 12
    ) -> Dict[str, Dict[str, Any]]:
        """
        Otimiza todos os modelos do ensemble.

        Args:
            model_configs: Lista de dicts com 'class', 'param_space'
            train_data: Dados de treino
            val_data: Dados de valida√ß√£o
            forecast_horizon: Horizonte de previs√£o

        Returns:
            Dict com melhores par√¢metros para cada modelo
        """
        all_best_params = {}

        for config in model_configs:
            model_class = config['class']
            param_space = config['param_space']

            best_params = self.optimize_model(
                model_class=model_class,
                train_data=train_data,
                val_data=val_data,
                param_space=param_space,
                forecast_horizon=forecast_horizon
            )

            all_best_params[model_class.__name__] = best_params

        return all_best_params

    def get_optimization_history(self) -> List[Dict]:
        """
        Retorna hist√≥rico completo de otimiza√ß√µes.

        Returns:
            Lista com hist√≥rico
        """
        return self.optimization_history

    def plot_optimization_history(self, model_name: Optional[str] = None):
        """
        Plota hist√≥rico de otimiza√ß√£o.

        Args:
            model_name: Nome do modelo (None = √∫ltimo)
        """
        try:
            from optuna.visualization import plot_optimization_history, plot_param_importances
            import matplotlib.pyplot as plt

            if self.study is None:
                print("‚ö†Ô∏è  Nenhuma otimiza√ß√£o realizada ainda.")
                return

            # Plot 1: Hist√≥rico
            fig1 = plot_optimization_history(self.study)
            fig1.show()

            # Plot 2: Import√¢ncia dos par√¢metros
            try:
                fig2 = plot_param_importances(self.study)
                fig2.show()
            except:
                pass  # Pode falhar se poucos trials

        except ImportError:
            print("‚ö†Ô∏è  Plotly n√£o instalado. Instale com: pip install plotly")


class RecursiveOptimizer:
    """
    Otimizador recursivo que ajusta hiperpar√¢metros durante o treinamento.

    A cada N epis√≥dios, reotimiza os hiperpar√¢metros baseado no desempenho recente.
    """

    def __init__(
        self,
        hyperparameter_optimizer: HyperparameterOptimizer,
        reoptimize_frequency: int = 50,
        performance_window: int = 20,
        improvement_threshold: float = 0.05
    ):
        """
        Inicializa o otimizador recursivo.

        Args:
            hyperparameter_optimizer: Otimizador de hiperpar√¢metros
            reoptimize_frequency: Reotimiza a cada N epis√≥dios
            performance_window: Janela para calcular performance
            improvement_threshold: Threshold de melhoria para reotimizar
        """
        self.hp_optimizer = hyperparameter_optimizer
        self.reoptimize_frequency = reoptimize_frequency
        self.performance_window = performance_window
        self.improvement_threshold = improvement_threshold

        self.episode_count = 0
        self.performance_history = []
        self.reoptimization_history = []

    def should_reoptimize(self, current_performance: float) -> bool:
        """
        Decide se deve reotimizar baseado no desempenho recente.

        Args:
            current_performance: Performance atual

        Returns:
            True se deve reotimizar
        """
        self.episode_count += 1
        self.performance_history.append(current_performance)

        # Verifica frequ√™ncia
        if self.episode_count % self.reoptimize_frequency != 0:
            return False

        # Verifica se h√° hist√≥rico suficiente
        if len(self.performance_history) < self.performance_window * 2:
            return False

        # Compara performance recente com anterior
        recent_perf = np.mean(self.performance_history[-self.performance_window:])
        previous_perf = np.mean(
            self.performance_history[-2*self.performance_window:-self.performance_window]
        )

        # Calcula melhoria
        if self.hp_optimizer.direction == 'minimize':
            improvement = (previous_perf - recent_perf) / previous_perf
        else:
            improvement = (recent_perf - previous_perf) / previous_perf

        # Reotimiza se n√£o melhorou o suficiente
        should_reopt = improvement < self.improvement_threshold

        if should_reopt:
            self.reoptimization_history.append({
                'episode': self.episode_count,
                'recent_performance': recent_perf,
                'previous_performance': previous_perf,
                'improvement': improvement
            })

        return should_reopt

    def reoptimize(
        self,
        model_configs: List[Dict],
        train_data: Union[np.ndarray, pd.Series],
        val_data: Union[np.ndarray, pd.Series],
        forecast_horizon: int = 12
    ) -> Dict[str, Dict[str, Any]]:
        """
        Executa reotimiza√ß√£o.

        Args:
            model_configs: Configura√ß√µes dos modelos
            train_data: Dados de treino
            val_data: Dados de valida√ß√£o
            forecast_horizon: Horizonte

        Returns:
            Novos melhores par√¢metros
        """
        print(f"\nüîÑ Reotimiza√ß√£o recursiva no epis√≥dio {self.episode_count}")

        new_params = self.hp_optimizer.optimize_ensemble(
            model_configs=model_configs,
            train_data=train_data,
            val_data=val_data,
            forecast_horizon=forecast_horizon
        )

        return new_params

    def get_reoptimization_history(self) -> List[Dict]:
        """Retorna hist√≥rico de reotimiza√ß√µes."""
        return self.reoptimization_history
