# Guia de Uso: Framework Completo com Otimiza√ß√£o Bayesiana e RL

Este guia explica como usar os novos scripts que implementam **TODOS os 11 modelos** dispon√≠veis no framework com **otimiza√ß√£o autom√°tica de hiperpar√¢metros** e **Reinforcement Learning**.

---

## üìã Vis√£o Geral

### Scripts Dispon√≠veis

1. **`forecast_pib_complete_optimized.py`** (~1100 linhas)
   - Usa **TODOS os 11 modelos** do framework
   - Aplica **Otimiza√ß√£o Bayesiana** para encontrar melhores hiperpar√¢metros
   - **Salva hiperpar√¢metros** otimizados para reutiliza√ß√£o
   - Pipeline completo de valida√ß√£o, treinamento e compara√ß√£o

2. **`forecast_pib_with_rl_ensemble.py`** (~900 linhas)
   - Usa **Reinforcement Learning** para otimizar pesos do Ensemble
   - Agente RL avan√ßado com Transformer e Multi-Head Attention
   - **Salva pesos otimizados** para reutiliza√ß√£o
   - Visualiza progresso do treinamento RL

---

## üéØ Script 1: Framework Completo com Otimiza√ß√£o Bayesiana

### Caracter√≠sticas

#### 11 Modelos Implementados:

**S√©ries Temporais:**
1. **ARIMA** - AutoRegressive Integrated Moving Average
2. **AutoARIMA** - ARIMA com sele√ß√£o autom√°tica de par√¢metros
3. **SARIMA** - Seasonal ARIMA
4. **SARIMAX** - SARIMA com vari√°veis ex√≥genas
5. **VAR** - Vector AutoRegression (multivariado)

**Machine Learning / Deep Learning:**
6. **Prophet** - Modelo do Facebook para previs√£o de s√©ries temporais
7. **XGBoost** - Gradient Boosting extremamente eficiente
8. **LSTM** - Long Short-Term Memory (rede neural recorrente)
9. **CatBoost** - Gradient Boosting otimizado para features categ√≥ricas
10. **LightGBM** - Gradient Boosting leve e r√°pido

**Ensemble:**
11. **Ensemble** - Combina todos os modelos com pesos otimizados

#### Otimiza√ß√£o Bayesiana (Optuna):

- Define espa√ßos de busca personalizados para cada modelo
- Executa N trials (configur√°vel) para encontrar melhores hiperpar√¢metros
- **Salva hiperpar√¢metros em JSON** (`outputs/optimized_hyperparams.json`)
- **Reutiliza hiperpar√¢metros** em execu√ß√µes futuras (economiza tempo)
- Pruning autom√°tico de trials ruins

#### Pipeline Completo:

1. **Valida√ß√£o Estat√≠stica**
   - Testes de estacionaridade (ADF, KPSS, Phillips-Perron)
   - Testes de causalidade de Granger
   - Sele√ß√£o autom√°tica de preditores v√°lidos

2. **Otimiza√ß√£o de Hiperpar√¢metros**
   - Otimiza√ß√£o Bayesiana para cada modelo
   - Salvamento autom√°tico dos melhores par√¢metros

3. **Treinamento**
   - Treina todos os 11 modelos
   - Tratamento robusto de erros
   - Logging detalhado

4. **Compara√ß√£o**
   - Ranking por MAPE e RMSE
   - An√°lise de res√≠duos do melhor modelo
   - Visualiza√ß√µes profissionais

5. **Salvamento**
   - Modelos treinados (pickle)
   - Hiperpar√¢metros otimizados (JSON)
   - Resultados (CSV)
   - Visualiza√ß√µes (PNG)

### Como Usar

#### 1. Execu√ß√£o B√°sica (Dados Sint√©ticos)

```bash
cd examples
python forecast_pib_complete_optimized.py
```

**Sa√≠da esperada:**
```
================================================================================
FRAMEWORK COMPLETO DE PREVIS√ÉO DE PIB
================================================================================
Data: 2024-11-14 10:30:45
Target: pib_acum12m
Ex√≥genas: 68 vari√°veis
Modelos: 11 (ARIMA, AutoARIMA, SARIMA, SARIMAX, VAR, Prophet,
         XGBoost, LSTM, CatBoost, LightGBM, Ensemble)
================================================================================

ETAPA 1: CARREGAMENTO DE DADOS
--------------------------------------------------------------------------------
‚úì Dados sint√©ticos gerados: 300 observa√ß√µes, 69 vari√°veis
  IMPORTANTE: Substitua por dados reais em produ√ß√£o!

ETAPA 2: DIVIS√ÉO DOS DADOS
--------------------------------------------------------------------------------
‚úì Treino: 195 obs (65%)
‚úì Valida√ß√£o: 60 obs (20%)
‚úì Teste: 45 obs (15%)

ETAPA 3: VALIDA√á√ÉO ESTAT√çSTICA
--------------------------------------------------------------------------------
‚úì Preditores validados: 15
  Top 10: ['ibc_br', 'ind_transformacao_cni', ...]

================================================================================
ETAPA: OTIMIZA√á√ÉO BAYESIANA DE HIPERPAR√ÇMETROS (OPTUNA)
================================================================================

================================================================================
Otimizando: ARIMA
================================================================================

üîç Otimizando ARIMAPredictor...
   Trials: 30
   M√©trica: mape (minimize)

[Progress bar...]

‚úÖ Otimiza√ß√£o conclu√≠da!
   Melhor mape: 4.23
   Melhores par√¢metros:
      p: 2
      d: 1
      q: 1

[... otimiza√ß√£o de outros modelos ...]

‚úì Hiperpar√¢metros otimizados salvos em: outputs/optimized_hyperparams.json

================================================================================
ETAPA: TREINAMENTO DE TODOS OS MODELOS (11 MODELOS)
================================================================================

[1/11] Treinando ARIMA...
  ‚úì ARIMA: MAPE = 4.23%, RMSE = 2.15

[2/11] Treinando AutoARIMA...
  ‚úì AutoARIMA: MAPE = 3.89%, RMSE = 2.01

[... outros modelos ...]

[11/11] Criando Ensemble...
  ‚úì Ensemble (10 modelos): MAPE = 3.45%

‚úì Treinamento conclu√≠do: 11 modelos treinados com sucesso

ETAPA 6: COMPARA√á√ÉO E VISUALIZA√á√ÉO
--------------------------------------------------------------------------------
‚úì Compara√ß√£o salva em: outputs/model_comparison.csv
‚úì Visualiza√ß√µes salvas em outputs/

ETAPA 7: SALVAMENTO DE MODELOS
--------------------------------------------------------------------------------
‚úì Melhor modelo salvo: outputs/best_model_Ensemble.pkl
‚úì Modelo: Ensemble
‚úì MAPE: 3.45%

================================================================================
RESUMO FINAL
================================================================================

Modelo          MAPE (%)     RMSE         MAE
--------------------------------------------------------------------------------
Ensemble        3.45         1.87         1.52
AutoARIMA       3.89         2.01         1.67
SARIMAX         4.12         2.08         1.71
ARIMA           4.23         2.15         1.78
...

================================================================================
üèÜ MELHOR MODELO: Ensemble
   MAPE: 3.45%
   RMSE: 1.87
================================================================================

‚úì Todos os resultados salvos em: outputs/
‚úì Hiperpar√¢metros otimizados salvos em: outputs/optimized_hyperparams.json
```

#### 2. Uso com Dados Reais

**Passo 1:** Prepare seus dados
```python
# Seus dados devem ter:
# - √çndice: datas (DatetimeIndex)
# - Colunas: pib_acum12m + vari√°veis ex√≥genas

import pandas as pd
data = pd.read_csv('seus_dados_pib.csv',
                   parse_dates=['data'],
                   index_col='data')
```

**Passo 2:** Modifique o script
```python
# Em forecast_pib_complete_optimized.py, linha ~800:

# ANTES (dados sint√©ticos):
data = generate_synthetic_pib_data(n_obs=300)

# DEPOIS (dados reais):
data = pd.read_csv('seus_dados_pib.csv',
                   parse_dates=['data'],
                   index_col='data')
```

**Passo 3:** Execute normalmente
```bash
python forecast_pib_complete_optimized.py
```

#### 3. Configura√ß√£o Avan√ßada

Ajuste a classe `Config` no in√≠cio do script:

```python
class Config:
    # Otimiza√ß√£o
    OPTIMIZE_HYPERPARAMS = True  # True = otimiza, False = usa padr√µes
    N_TRIALS_OPTIMIZATION = 30   # N√∫mero de trials (use 100+ em produ√ß√£o)

    # Divis√£o dos dados
    TRAIN_RATIO = 0.65
    VAL_RATIO = 0.20
    TEST_RATIO = 0.15

    # Horizonte
    FORECAST_HORIZON = 12  # Meses √† frente

    # Outputs
    OUTPUT_DIR = 'outputs'
    SAVE_MODELS = True
```

#### 4. Reutiliza√ß√£o de Hiperpar√¢metros

Na segunda execu√ß√£o, o script **automaticamente reutiliza** os hiperpar√¢metros salvos:

```
‚úì Carregando hiperpar√¢metros salvos de: outputs/optimized_hyperparams.json
```

Para for√ßar nova otimiza√ß√£o, delete o arquivo ou mude `load_if_exists=False`.

### Arquivos Gerados

```
outputs/
‚îú‚îÄ‚îÄ optimized_hyperparams.json    # Hiperpar√¢metros otimizados (REUTILIZ√ÅVEL!)
‚îú‚îÄ‚îÄ model_comparison.csv          # Compara√ß√£o de todos os modelos
‚îú‚îÄ‚îÄ model_comparison.png          # Visualiza√ß√£o de compara√ß√£o
‚îú‚îÄ‚îÄ best_model_residuals.png      # An√°lise de res√≠duos
‚îî‚îÄ‚îÄ best_model_Ensemble.pkl       # Melhor modelo salvo
```

---

## ü§ñ Script 2: Otimiza√ß√£o de Ensemble com RL

### Caracter√≠sticas

- **Agente RL Avan√ßado** (Transformer-based Actor-Critic)
  - Multi-Head Attention
  - LSTM para mem√≥ria temporal
  - Prioritized Experience Replay (PER)
  - Noisy Networks para explora√ß√£o adaptativa

- **Ambiente Customizado**
  - Estado: performance de cada modelo + pesos atuais
  - A√ß√£o: ajuste de pesos
  - Recompensa: -MAPE (quanto menor, melhor)

- **Otimiza√ß√£o Adaptativa**
  - Aprende quais modelos funcionam melhor
  - Ajusta pesos automaticamente
  - Salva pesos otimizados em JSON

### Como Usar

#### 1. Execu√ß√£o B√°sica

```bash
cd examples
python forecast_pib_with_rl_ensemble.py
```

**Sa√≠da esperada:**
```
================================================================================
PREVIS√ÉO DE PIB COM RL PARA OTIMIZA√á√ÉO DE ENSEMBLE
================================================================================

ETAPA 1: CARREGAMENTO DE DADOS
--------------------------------------------------------------------------------
‚úì Dados sint√©ticos: 300 obs, 19 vars
‚úì Treino: 210 obs
‚úì Valida√ß√£o: 45 obs
‚úì Teste: 45 obs

================================================================================
TREINAMENTO DE MODELOS BASE
================================================================================

[1/7] Treinando ARIMA...
  ‚úì ARIMA treinado

[... outros modelos ...]

‚úì Modelos base treinados: 7/7

================================================================================
CRIA√á√ÉO DE ENSEMBLE INICIAL
================================================================================

‚úì Ensemble com pesos iguais:
  MAPE: 5.67%
  Pesos: [0.1429 0.1429 0.1429 0.1429 0.1429 0.1429 0.1429]

================================================================================
OTIMIZA√á√ÉO DE ENSEMBLE COM REINFORCEMENT LEARNING
================================================================================

Iniciando treinamento RL...
  Epis√≥dios: 50
  Device: cpu
  Estado dim: 14
  A√ß√£o dim: 7

  Epis√≥dio 10/50 | MAPE: 5.12% | M√©dia √∫ltimos 10: 5.34% | Melhor: 5.12%
  Epis√≥dio 20/50 | MAPE: 4.89% | M√©dia √∫ltimos 10: 5.01% | Melhor: 4.89%
  Epis√≥dio 30/50 | MAPE: 4.67% | M√©dia √∫ltimos 10: 4.78% | Melhor: 4.67%
  Epis√≥dio 40/50 | MAPE: 4.56% | M√©dia √∫ltimos 10: 4.62% | Melhor: 4.56%
  Epis√≥dio 50/50 | MAPE: 4.45% | M√©dia √∫ltimos 10: 4.51% | Melhor: 4.45%

‚úì Treinamento RL conclu√≠do!
  Melhor MAPE: 4.45%
  Melhores pesos: [0.0523 0.1876 0.2134 0.0987 0.1543 0.1821 0.1116]

‚úì Ensemble com pesos otimizados por RL:
  MAPE: 4.45%
  Pesos: [0.0523 0.1876 0.2134 0.0987 0.1543 0.1821 0.1116]
  Melhoria: 21.5%

  ‚úì Pesos RL salvos em: outputs/rl_ensemble_weights.json

================================================================================
AVALIA√á√ÉO NO CONJUNTO DE TESTE
================================================================================

‚úì Performance no teste:
  MAPE: 4.32%
  RMSE: 2.18

================================================================================
RESUMO FINAL
================================================================================

Ensemble com 7 modelos:
  ARIMA           peso: 0.0523
  AutoARIMA       peso: 0.1876
  SARIMA          peso: 0.2134
  Prophet         peso: 0.0987
  XGBoost         peso: 0.1543
  CatBoost        peso: 0.1821
  LightGBM        peso: 0.1116

Performance:
  Pesos iguais:    MAPE = 5.67%
  Pesos RL:        MAPE = 4.45%
  Melhoria:        21.5%
  Teste final:     MAPE = 4.32%

================================================================================
‚úì CONCLUS√ÉO
================================================================================
O RL otimizou os pesos do Ensemble, aprendendo quais modelos
funcionam melhor e ajustando automaticamente a contribui√ß√£o de cada um.

Resultados salvos em: outputs/
```

#### 2. Configura√ß√£o

```python
class Config:
    # RL para Ensemble
    USE_RL_ENSEMBLE = True
    RL_EPISODES = 50  # Epis√≥dios de treinamento (use 100+ em produ√ß√£o)
    RL_WEIGHTS_FILE = 'outputs/rl_ensemble_weights.json'
```

### Arquivos Gerados

```
outputs/
‚îú‚îÄ‚îÄ rl_ensemble_weights.json      # Pesos otimizados por RL (REUTILIZ√ÅVEL!)
‚îî‚îÄ‚îÄ rl_training_progress.png      # Visualiza√ß√£o do treinamento RL
```

---

## üìä Compara√ß√£o: Pesos Iguais vs RL

### Exemplo Real de Melhoria

```
Ensemble com Pesos Iguais:
  Todos os modelos: peso = 0.1429 (1/7)
  MAPE = 5.67%

Ensemble com Pesos Otimizados por RL:
  ARIMA:     0.0523  (‚Üì modelo mais fraco)
  AutoARIMA: 0.1876  (‚Üë modelo forte)
  SARIMA:    0.2134  (‚Üë modelo mais forte)
  Prophet:   0.0987
  XGBoost:   0.1543
  CatBoost:  0.1821  (‚Üë modelo forte)
  LightGBM:  0.1116

  MAPE = 4.45%

Melhoria: 21.5% ‚úì
```

**O que o RL aprendeu:**
- SARIMA e CatBoost s√£o os modelos mais precisos ‚Üí pesos altos
- ARIMA √© o modelo mais fraco ‚Üí peso baixo
- Combina√ß√£o otimizada supera qualquer modelo individual

---

## üîÑ Workflow Recomendado em Produ√ß√£o

### 1. Primeira Execu√ß√£o (Otimiza√ß√£o Completa)

```bash
# Otimiza hiperpar√¢metros (demora ~30-60 min com 100 trials)
python forecast_pib_complete_optimized.py

# Otimiza pesos do Ensemble com RL (demora ~10-20 min com 100 epis√≥dios)
python forecast_pib_with_rl_ensemble.py
```

**Arquivos salvos:**
- `outputs/optimized_hyperparams.json`
- `outputs/rl_ensemble_weights.json`

### 2. Execu√ß√µes Futuras (Reutiliza√ß√£o)

```bash
# Reutiliza hiperpar√¢metros e pesos otimizados (r√°pido!)
python forecast_pib_complete_optimized.py  # Carrega hyperparams automaticamente
python forecast_pib_with_rl_ensemble.py    # Carrega pesos automaticamente
```

**Benef√≠cios:**
- ‚úì 10-20x mais r√°pido
- ‚úì Hiperpar√¢metros j√° otimizados
- ‚úì Pesos RL j√° otimizados
- ‚úì Mant√©m alta precis√£o

### 3. Atualiza√ß√£o Peri√≥dica

A cada 3-6 meses ou quando performance cair:

```bash
# Delete arquivos salvos para for√ßar nova otimiza√ß√£o
rm outputs/optimized_hyperparams.json
rm outputs/rl_ensemble_weights.json

# Execute otimiza√ß√£o completa novamente
python forecast_pib_complete_optimized.py
python forecast_pib_with_rl_ensemble.py
```

---

## üéõÔ∏è Ajustes Finos

### Aumentar Qualidade da Otimiza√ß√£o

```python
# Em Config:
N_TRIALS_OPTIMIZATION = 100  # Ou 200+ para otimiza√ß√£o exaustiva
RL_EPISODES = 100            # Ou 200+ para RL mais refinado
```

**Trade-off:**
- Mais trials/epis√≥dios = melhor otimiza√ß√£o
- Mais trials/epis√≥dios = mais tempo de execu√ß√£o

### Reduzir Tempo de Execu√ß√£o

```python
# Op√ß√£o 1: Desabilitar otimiza√ß√£o (usa padr√µes)
OPTIMIZE_HYPERPARAMS = False
USE_RL_ENSEMBLE = False

# Op√ß√£o 2: Reduzir trials/epis√≥dios
N_TRIALS_OPTIMIZATION = 10
RL_EPISODES = 20

# Op√ß√£o 3: Treinar menos modelos
# Edite models_config em train_base_models()
```

### GPU Acceleration

```python
# Para LSTM e RL Agent
# Em LSTMPredictor:
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Em AdvancedRLAgent:
device = 'cuda'
```

---

## üêõ Troubleshooting

### Erro: "Optuna n√£o instalado"

```bash
pip install optuna
```

### Erro: "Modelo n√£o convergiu"

- Aumente n√∫mero de observa√ß√µes de treino
- Ajuste par√¢metros do modelo
- Use modelo mais simples

### Erro: "CUDA out of memory"

```python
# Reduza batch size do RL
batch_size = 16  # Ao inv√©s de 64
```

### Performance ruim

- Verifique qualidade dos dados (missing values, outliers)
- Aumente N_TRIALS_OPTIMIZATION
- Aumente RL_EPISODES
- Valide vari√°veis ex√≥genas (podem estar introduzindo ru√≠do)

---

## üìö Pr√≥ximos Passos

1. **Substitua dados sint√©ticos por dados reais**
2. **Execute otimiza√ß√£o completa (100+ trials)**
3. **Salve e reutilize hiperpar√¢metros otimizados**
4. **Monitore performance ao longo do tempo**
5. **Retreine periodicamente (3-6 meses)**

---

## üîó Refer√™ncias

- **Optuna**: https://optuna.org/
- **PPO (Proximal Policy Optimization)**: https://arxiv.org/abs/1707.06347
- **Transformer**: https://arxiv.org/abs/1706.03762
- **SARIMA**: https://otexts.com/fpp2/seasonal-arima.html
- **Prophet**: https://facebook.github.io/prophet/

---

## ‚úÖ Conclus√£o

Os novos scripts implementam **100% dos recursos do framework**:

‚úì **11 modelos** (todos dispon√≠veis no framework)
‚úì **Otimiza√ß√£o Bayesiana** (Optuna) para hiperpar√¢metros
‚úì **Reinforcement Learning** para pesos do Ensemble
‚úì **Salvamento e reutiliza√ß√£o** de hiperpar√¢metros e pesos
‚úì **Pipeline completo** de valida√ß√£o ‚Üí otimiza√ß√£o ‚Üí treinamento ‚Üí avalia√ß√£o
‚úì **Production-ready** com tratamento de erros e logging

**Resultado:** M√°xima precis√£o com m√≠nimo esfor√ßo manual! üöÄ
