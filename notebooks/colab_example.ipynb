{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ Framework de RL para Previs√£o de Ciclos Econ√¥micos\n",
    "\n",
    "**Framework avan√ßado que combina Reinforcement Learning com modelos supervisionados para previs√£o de s√©ries temporais.**\n",
    "\n",
    "Este notebook demonstra o uso completo no Google Colab.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Conte√∫do\n",
    "1. Setup e Instala√ß√£o\n",
    "2. Gera√ß√£o de Dados\n",
    "3. Cria√ß√£o de Modelos Base\n",
    "4. Ambiente de RL\n",
    "5. Treinamento do Agente\n",
    "6. Avalia√ß√£o e Resultados\n",
    "7. Visualiza√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1Ô∏è‚É£ Setup e Instala√ß√£o\n",
    "\n",
    "Clone o reposit√≥rio e instale depend√™ncias (leva ~2 minutos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Clone reposit√≥rio\n",
    "!git clone https://github.com/cbaracho200/Previs-o-ciclos-Econ-mico.git\n",
    "%cd Previs-o-ciclos-Econ-mico\n",
    "\n",
    "# Instala depend√™ncias\n",
    "!pip install -q torch gymnasium statsmodels pmdarima xgboost pandas numpy matplotlib seaborn tqdm scikit-learn\n",
    "\n",
    "print(\"\\n‚úÖ Instala√ß√£o conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "### Imports e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports-code"
   },
   "outputs": [],
   "source": "import sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configura√ß√£o de estilo\nplt.style.use('default')\nplt.rcParams['figure.figsize'] = (12, 6)\n\n# Adiciona src ao path\nsys.path.insert(0, '/content/Previs-o-ciclos-Econ-mico')\n\n# Imports do framework\nfrom src.utils.data_utils import generate_synthetic_data, split_data\nfrom src.models.arima_model import ARIMAPredictor\nfrom src.models.lstm_model import LSTMPredictor\nfrom src.models.xgboost_model import XGBoostPredictor\nfrom src.models.ensemble_predictor import EnsemblePredictor\nfrom src.environments.timeseries_env import TimeSeriesEnv\nfrom src.agents.rl_agent import RLAgent\nfrom src.training.trainer import RLTrainer\nfrom src.utils.visualization import plot_predictions, plot_coefficients\nfrom src.utils.metrics import calculate_metrics\n\nprint(\"‚úÖ Imports realizados com sucesso!\")\n\n# Tenta importar agente avan√ßado\ntry:\n    from src.agents.rl_agent_advanced import AdvancedRLAgent\n    from src.training.trainer_advanced import AdvancedRLTrainer\n    print(\"‚úÖ Agente Avan√ßado (PhD) dispon√≠vel!\")\n    ADVANCED_AVAILABLE = True\nexcept ImportError as e:\n    print(f\"‚ö†Ô∏è  Agente Avan√ßado n√£o dispon√≠vel (use RLAgent padr√£o)\")\n    print(f\"   Erro: {e}\")\n    ADVANCED_AVAILABLE = False"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data"
   },
   "source": [
    "## 2Ô∏è‚É£ Gera√ß√£o de Dados\n",
    "\n",
    "Gera dados sint√©ticos de s√©ries temporais com tend√™ncia, sazonalidade e ru√≠do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-gen"
   },
   "outputs": [],
   "source": [
    "# Gera dados sint√©ticos\n",
    "print(\"Gerando dados sint√©ticos...\")\n",
    "data = generate_synthetic_data(\n",
    "    n_points=300,\n",
    "    trend=0.05,\n",
    "    seasonality_amplitude=15.0,\n",
    "    seasonality_period=12,\n",
    "    noise_std=3.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Divide dados\n",
    "train_data, val_data, test_data = split_data(\n",
    "    data, \n",
    "    train_ratio=0.7, \n",
    "    val_ratio=0.15\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dados gerados: {len(data)} pontos\")\n",
    "print(f\"   ‚Ä¢ Treino: {len(train_data)} pontos\")\n",
    "print(f\"   ‚Ä¢ Valida√ß√£o: {len(val_data)} pontos\")\n",
    "print(f\"   ‚Ä¢ Teste: {len(test_data)} pontos\")\n",
    "\n",
    "# Visualiza dados\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(data['date'], data['value'], linewidth=2, label='Dados Completos', alpha=0.8)\n",
    "plt.axvline(x=train_data['date'].iloc[-1], color='red', linestyle='--', \n",
    "            linewidth=2, label='Fim Treino', alpha=0.7)\n",
    "plt.axvline(x=val_data['date'].iloc[-1], color='orange', linestyle='--', \n",
    "            linewidth=2, label='Fim Valida√ß√£o', alpha=0.7)\n",
    "plt.xlabel('Data', fontsize=12)\n",
    "plt.ylabel('Valor', fontsize=12)\n",
    "plt.title('S√©rie Temporal Sint√©tica - Divis√£o dos Dados', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estat√≠sticas descritivas\n",
    "print(\"\\nüìä Estat√≠sticas dos dados:\")\n",
    "print(data['value'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "models"
   },
   "source": [
    "## 3Ô∏è‚É£ Cria√ß√£o de Modelos Base\n",
    "\n",
    "Cria tr√™s modelos supervisionados:\n",
    "- **ARIMA**: Captura tend√™ncias lineares e sazonalidades\n",
    "- **LSTM**: Captura depend√™ncias de longo prazo\n",
    "- **XGBoost**: Captura rela√ß√µes n√£o-lineares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "models-create"
   },
   "outputs": [],
   "source": [
    "print(\"üîß Criando modelos base...\\n\")\n",
    "\n",
    "models = [\n",
    "    ARIMAPredictor(\n",
    "        order=(2, 1, 2), \n",
    "        name=\"ARIMA\"\n",
    "    ),\n",
    "    LSTMPredictor(\n",
    "        lookback=12, \n",
    "        hidden_size=32, \n",
    "        num_layers=2, \n",
    "        epochs=30,  # Reduzido para Colab\n",
    "        batch_size=16,\n",
    "        name=\"LSTM\"\n",
    "    ),\n",
    "    XGBoostPredictor(\n",
    "        lookback=12, \n",
    "        n_estimators=50,\n",
    "        max_depth=4,\n",
    "        name=\"XGBoost\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ {len(models)} modelos criados:\")\n",
    "for model in models:\n",
    "    print(f\"   ‚Ä¢ {model.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ensemble"
   },
   "source": [
    "### Cria√ß√£o e Treinamento do Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ensemble-train"
   },
   "outputs": [],
   "source": [
    "print(\"üîÑ Criando e treinando ensemble...\\n\")\n",
    "\n",
    "ensemble = EnsemblePredictor(models)\n",
    "ensemble.fit(train_data['value'])\n",
    "\n",
    "print(\"\\n‚úÖ Ensemble criado e treinado!\")\n",
    "print(f\"\\nüìä Pesos iniciais (iguais): {ensemble.get_weights()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl-env"
   },
   "source": [
    "## 4Ô∏è‚É£ Ambiente de RL\n",
    "\n",
    "Cria o ambiente Gymnasium customizado para otimiza√ß√£o de s√©ries temporais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "env-create"
   },
   "outputs": [],
   "source": [
    "print(\"üåç Criando ambiente de RL...\\n\")\n",
    "\n",
    "FORECAST_HORIZON = 6  # Previs√£o de 6 meses √† frente\n",
    "WINDOW_SIZE = 24      # Janela de observa√ß√£o de 24 pontos\n",
    "\n",
    "env = TimeSeriesEnv(\n",
    "    data=train_data,\n",
    "    forecast_horizon=FORECAST_HORIZON,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    n_coefficients=len(models),\n",
    "    max_steps=50\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Ambiente criado com sucesso!\")\n",
    "print(f\"\\nüìã Configura√ß√£o:\")\n",
    "print(f\"   ‚Ä¢ Horizonte de previs√£o: {env.forecast_horizon} meses\")\n",
    "print(f\"   ‚Ä¢ Janela de observa√ß√£o: {env.window_size} pontos\")\n",
    "print(f\"   ‚Ä¢ N√∫mero de coeficientes: {env.n_coefficients}\")\n",
    "print(f\"   ‚Ä¢ Dimens√£o do estado: {env.observation_space.shape[0]}\")\n",
    "print(f\"   ‚Ä¢ Dimens√£o da a√ß√£o: {env.action_space.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agent"
   },
   "source": [
    "### Cria√ß√£o do Agente RL (PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agent-create"
   },
   "outputs": [],
   "source": [
    "print(\"ü§ñ Criando agente RL (PPO)...\\n\")\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "\n",
    "agent = RLAgent(\n",
    "    state_dim=state_dim,\n",
    "    action_dim=action_dim,\n",
    "    learning_rate=3e-4,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_epsilon=0.2,\n",
    "    hidden_dim=128,\n",
    "    device='cpu'  # Mude para 'cuda' se tiver GPU habilitada\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Agente PPO criado!\")\n",
    "print(f\"\\nüß† Arquitetura:\")\n",
    "print(f\"   ‚Ä¢ Dimens√£o do estado: {state_dim}\")\n",
    "print(f\"   ‚Ä¢ Dimens√£o da a√ß√£o: {action_dim}\")\n",
    "print(f\"   ‚Ä¢ Camadas ocultas: 128 neur√¥nios\")\n",
    "print(f\"   ‚Ä¢ Algoritmo: Proximal Policy Optimization (PPO)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### ‚ö†Ô∏è IMPORTANTE: Use as Dimens√µes Corretas!\n\n**ERRO COMUM**: Nunca use valores hardcoded como `state_dim=44` ou `action_dim=10`!\n\n**CORRETO**: Sempre pegue do ambiente:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 5Ô∏è‚É£ Treinamento do Agente\n",
    "\n",
    "‚è∞ **Aten√ß√£o**: Esta c√©lula pode levar 5-10 minutos no Colab gratuito.\n",
    "\n",
    "O agente aprender√° os melhores coeficientes para combinar os modelos."
   ]
  },
  {
   "cell_type": "code",
   "source": "# üí° OPCIONAL: Use este c√≥digo para treinar com o agente avan√ßado\n# Descomente para usar (requer ~2-3GB RAM adicional)\n\nif ADVANCED_AVAILABLE:\n    print(\"üéì Treinando com Agente Avan√ßado (PhD)...\\n\")\n    print(\"‚è∞ Tempo estimado: 10-15 minutos no Colab gratuito\\n\")\n    \n    # Cria agente avan√ßado\n    advanced_agent = AdvancedRLAgent(\n        state_dim=env.observation_space.shape[0],  # ‚úÖ CORRETO: pega do ambiente\n        action_dim=env.action_space.shape[0],      # ‚úÖ CORRETO: pega do ambiente\n        learning_rate=1e-4,\n        hidden_dim=256,        # Reduzido para Colab (use 512 com GPU)\n        num_heads=4,           # Reduzido para Colab (use 8 com GPU)\n        num_layers=2,          # Reduzido para Colab (use 3 com GPU)\n        use_per=True,\n        use_noisy=True,\n        use_lstm=True,\n        device='cpu'           # Mude para 'cuda' se tiver GPU\n    )\n    \n    # Cria trainer avan√ßado\n    advanced_trainer = AdvancedRLTrainer(\n        env, \n        advanced_agent, \n        ensemble,\n        use_curriculum=True\n    )\n    \n    # Treina\n    advanced_history = advanced_trainer.train(\n        n_episodes=100,        # Use 200-500 em produ√ß√£o\n        max_steps=50,\n        eval_frequency=25,\n        early_stopping=True,\n        verbose=True\n    )\n    \n    # Substitui trainer e agent pelas vers√µes avan√ßadas\n    trainer = advanced_trainer\n    agent = advanced_agent\n    history = advanced_history\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"üéâ TREINAMENTO AVAN√áADO CONCLU√çDO!\")\n    print(\"=\"*80)\nelse:\n    print(\"‚ö†Ô∏è  Agente Avan√ßado n√£o dispon√≠vel. Use o treinamento padr√£o acima.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## üéì ALTERNATIVA: Agente Avan√ßado (N√≠vel PhD)\n\n**Quer resultados ainda melhores?** Use o AdvancedRLAgent com t√©cnicas state-of-the-art!\n\n### Caracter√≠sticas:\n- ‚úÖ Transformer-based Actor-Critic\n- ‚úÖ Multi-Head Attention (8 heads)\n- ‚úÖ Prioritized Experience Replay (PER)\n- ‚úÖ Noisy Networks (explora√ß√£o adaptativa)\n- ‚úÖ LSTM Memory\n- ‚úÖ Adaptive Entropy Regularization\n- ‚úÖ Curriculum Learning\n\n**‚ö†Ô∏è Requer mais RAM e tempo de treinamento**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-run"
   },
   "outputs": [],
   "source": [
    "print(\"üéØ Iniciando treinamento do agente RL...\\n\")\n",
    "print(\"‚è∞ Tempo estimado: 5-10 minutos no Colab gratuito\\n\")\n",
    "\n",
    "trainer = RLTrainer(env, agent, ensemble)\n",
    "\n",
    "# Treinamento (reduzido para Colab)\n",
    "history = trainer.train(\n",
    "    n_episodes=100,      # Use 200-500 em produ√ß√£o\n",
    "    max_steps=50,\n",
    "    eval_frequency=25,\n",
    "    save_frequency=50,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ TREINAMENTO CONCLU√çDO!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## 6Ô∏è‚É£ Avalia√ß√£o e Resultados\n",
    "\n",
    "Avalia o agente treinado e extrai os melhores coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eval-run"
   },
   "outputs": [],
   "source": [
    "print(\"üìä Avaliando modelo treinado...\\n\")\n",
    "\n",
    "# Avalia√ß√£o\n",
    "eval_results = trainer.evaluate(\n",
    "    n_episodes=10, \n",
    "    deterministic=True, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Extrai melhores coeficientes\n",
    "best_coefficients = trainer.get_best_coefficients()\n",
    "\n",
    "if best_coefficients is not None:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"üèÜ MELHORES COEFICIENTES ENCONTRADOS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for i, (model, coef) in enumerate(zip(models, best_coefficients)):\n",
    "        print(f\"   {model.name:12s}: {coef:.4f} ({coef*100:.1f}%)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Atualiza ensemble com melhores coeficientes\n",
    "    ensemble.update_weights(best_coefficients)\n",
    "    print(\"‚úÖ Ensemble atualizado com coeficientes otimizados!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Coeficientes n√£o dispon√≠veis, usando pesos iguais.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "### Teste no Conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-run"
   },
   "outputs": [],
   "source": [
    "print(\"üß™ Testando no conjunto de teste...\\n\")\n",
    "\n",
    "# Retreina ensemble com treino + valida√ß√£o\n",
    "full_train_data = pd.concat([train_data, val_data])\n",
    "ensemble.fit(full_train_data['value'])\n",
    "\n",
    "# Faz previs√£o\n",
    "forecast_horizon = 12\n",
    "predictions = ensemble.predict(steps=forecast_horizon)\n",
    "\n",
    "# Limita ao tamanho dos dados de teste\n",
    "actual_values = test_data['value'].values[:forecast_horizon]\n",
    "predictions = predictions[:len(actual_values)]\n",
    "\n",
    "# Calcula m√©tricas\n",
    "metrics = calculate_metrics(actual_values, predictions)\n",
    "\n",
    "# Exibe resultados\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"{'RESULTADOS NO CONJUNTO DE TESTE':^70}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüìà M√©tricas de Precis√£o:\")\n",
    "print(f\"   ‚Ä¢ MAPE (Mean Absolute % Error): {metrics['mape']:8.2f}%\")\n",
    "print(f\"   ‚Ä¢ RMSE (Root Mean Squared Error): {metrics['rmse']:8.4f}\")\n",
    "print(f\"   ‚Ä¢ MAE  (Mean Absolute Error):     {metrics['mae']:8.4f}\")\n",
    "print(f\"   ‚Ä¢ R¬≤   (Coef. Determina√ß√£o):      {metrics['r2']:8.4f}\")\n",
    "print(f\"   ‚Ä¢ Acur√°cia Direcional:            {metrics['directional_accuracy']:8.2f}%\")\n",
    "print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "# Interpreta√ß√£o\n",
    "if metrics['mape'] < 5:\n",
    "    interpretation = \"üåü EXCELENTE!\"\n",
    "elif metrics['mape'] < 10:\n",
    "    interpretation = \"‚úÖ MUITO BOM!\"\n",
    "elif metrics['mape'] < 15:\n",
    "    interpretation = \"üëç BOM!\"\n",
    "else:\n",
    "    interpretation = \"‚ö†Ô∏è ACEIT√ÅVEL (pode melhorar com mais treinamento)\"\n",
    "\n",
    "print(f\"üí° Interpreta√ß√£o: {interpretation}\")\n",
    "print(f\"\\nMAPE < 5% = Excelente | 5-10% = Muito Bom | 10-15% = Bom | >15% = Aceit√°vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viz"
   },
   "source": [
    "## 7Ô∏è‚É£ Visualiza√ß√µes\n",
    "\n",
    "Gera gr√°ficos detalhados dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-predictions"
   },
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o 1: Previs√µes vs Valores Reais\n",
    "print(\"üìä Gerando visualiza√ß√µes...\\n\")\n",
    "\n",
    "plot_predictions(\n",
    "    actual_values,\n",
    "    predictions,\n",
    "    title=f\"Ensemble Otimizado por RL - Teste (MAPE: {metrics['mape']:.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-coefficients"
   },
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o 2: Coeficientes Otimizados\n",
    "if best_coefficients is not None:\n",
    "    plot_coefficients(\n",
    "        best_coefficients,\n",
    "        model_names=[m.name for m in models],\n",
    "        title=\"Coeficientes Otimizados pelo Agente RL (PPO)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Coeficientes n√£o dispon√≠veis para visualiza√ß√£o.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-training"
   },
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o 3: Hist√≥rico de Treinamento\n",
    "trainer.plot_training_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison"
   },
   "source": [
    "### Compara√ß√£o: Antes vs Depois do RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison-code"
   },
   "outputs": [],
   "source": [
    "# Compara ensemble com pesos iguais vs otimizados\n",
    "print(\"üîÑ Comparando resultados...\\n\")\n",
    "\n",
    "# Ensemble com pesos iguais\n",
    "ensemble_equal = EnsemblePredictor(models, weights=np.ones(len(models)))\n",
    "ensemble_equal.fit(full_train_data['value'])\n",
    "predictions_equal = ensemble_equal.predict(steps=len(actual_values))\n",
    "\n",
    "# M√©tricas do ensemble com pesos iguais\n",
    "metrics_equal = calculate_metrics(actual_values, predictions_equal)\n",
    "\n",
    "# Tabela de compara√ß√£o\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"{'COMPARA√á√ÉO: ENSEMBLE COM PESOS IGUAIS vs OTIMIZADO POR RL':^80}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n{'M√©trica':<25} {'Pesos Iguais':>15} {'Otimizado RL':>15} {'Melhoria':>15}\")\n",
    "print(f\"{'-'*80}\")\n",
    "\n",
    "for metric_name in ['mape', 'rmse', 'mae', 'r2']:\n",
    "    equal_val = metrics_equal[metric_name]\n",
    "    optim_val = metrics[metric_name]\n",
    "    \n",
    "    if metric_name == 'r2':\n",
    "        improvement = ((optim_val - equal_val) / abs(equal_val)) * 100\n",
    "        print(f\"{metric_name.upper():<25} {equal_val:>15.4f} {optim_val:>15.4f} {improvement:>+14.1f}%\")\n",
    "    else:\n",
    "        improvement = ((equal_val - optim_val) / equal_val) * 100\n",
    "        print(f\"{metric_name.upper():<25} {equal_val:>15.4f} {optim_val:>15.4f} {improvement:>+14.1f}%\")\n",
    "\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"\\nüí° Valores positivos em 'Melhoria' indicam que o RL otimizou o ensemble!\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save"
   },
   "source": [
    "## üíæ Salvando Resultados\n",
    "\n",
    "Opcional: Salve o modelo treinado no Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-drive"
   },
   "outputs": [],
   "source": [
    "# Descomente para salvar no Google Drive\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Salva checkpoint\n",
    "# import os\n",
    "# save_dir = '/content/drive/MyDrive/rl_forecasting_models'\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# # Salva modelo\n",
    "# agent.save(f'{save_dir}/agent_model.pt')\n",
    "# print(f\"‚úÖ Modelo salvo em: {save_dir}\")\n",
    "\n",
    "# # Salva coeficientes\n",
    "# if best_coefficients is not None:\n",
    "#     np.save(f'{save_dir}/best_coefficients.npy', best_coefficients)\n",
    "#     print(f\"‚úÖ Coeficientes salvos!\")\n",
    "\n",
    "print(\"\\nüí° Descomente o c√≥digo acima para salvar no Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next-steps"
   },
   "source": [
    "## üéØ Pr√≥ximos Passos\n",
    "\n",
    "### 1. Use seus pr√≥prios dados\n",
    "```python\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "data = pd.read_csv(list(uploaded.keys())[0])\n",
    "# Certifique-se de ter uma coluna 'value'\n",
    "```\n",
    "\n",
    "### 2. Ajuste hiperpar√¢metros\n",
    "- Aumente `n_episodes` para melhor treinamento (200-500)\n",
    "- Ajuste `learning_rate` do agente (1e-4 a 1e-3)\n",
    "- Modifique `forecast_horizon` (6-12 meses)\n",
    "\n",
    "### 3. Adicione mais modelos\n",
    "```python\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "# Implemente seu pr√≥prio modelo baseado em BasePredictor\n",
    "```\n",
    "\n",
    "### 4. Ative GPU no Colab\n",
    "- `Runtime > Change runtime type > GPU`\n",
    "- Mude `device='cuda'` no agente\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Documenta√ß√£o Completa\n",
    "\n",
    "Visite o [README do projeto](https://github.com/cbaracho200/Previs-o-ciclos-Econ-mico) para mais informa√ß√µes!\n",
    "\n",
    "---\n",
    "\n",
    "**Desenvolvido com ‚ù§Ô∏è para previs√£o de ciclos econ√¥micos usando Reinforcement Learning**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}